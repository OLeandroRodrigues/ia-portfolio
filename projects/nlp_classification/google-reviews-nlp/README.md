# ğŸ“ Google Reviews NLP Pipeline

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

This repository contains an **experimental NLP pipeline** to analyze and classify **Google Reviews**.
The project is organized into **two layers**:

1. **Comment Classification**
   - ğŸ­ **Sentiment analysis** (`positive | neutral | negative`)
   - ğŸ·ï¸ **Topic classification** (e.g., service, price, quality)
   - ğŸš¨ **Spam/legitimacy detection** (`suspect | legitimate`)

2. **Author Linking Experiments**
   - ğŸ” Detects possible **same-author patterns across different accounts**
   - âœï¸ Based on **writing fingerprint + semantic embeddings + clustering**

---

## ğŸ¯ Objectives
- âœ… Train and evaluate **classification models** using TensorFlow.
- âœ… Extract **stylometry features** and multilingual embeddings.
- âœ… Build similarity graphs to detect **repeated authorship**.
- âœ… Provide explainable outputs for research and audit.

---

## ğŸ·ï¸ Labeling Strategy (heuristics)

The file [`reviews_labeled.csv`](data/processed/reviews_labeled.csv) is generated automatically by the script [`src/data/heuristics_labeling.py`](src/data/heuristics_labeling.py).  

The labeling is based **only on ratings (stars)** and simple patterns inside the review message.  
No natural language understanding is applied at this stage.

**Rules:**

- If the row had a numeric `rating`:
  - `â‰¥ 4.0` â†’ **positive**  
  - `â‰¤ 2.0` â†’ **negative**  
  - `2.1 â€“ 3.9` â†’ **neutral**

- If the row had no `rating`, but the `message` contained explicit patterns like `x/5` (e.g. *â€œComida: 1/5, ServiÃ§o: 4/5, Ambiente: 5/5â€*):  
  - All values are collected  
  - The **median** is calculated  
  - Converted to **positive / neutral / negative** with the same rules above

- If the row had neither `rating` nor `x/5` patterns in the `message`:  
  - `label = None`  
  - The row is discarded in the final output  

âš ï¸ **Important:** at this stage the **free text message is not used** (e.g., *â€œo atendimento foi horrÃ­velâ€*, *â€œdoces maravilhososâ€*).  
Thatâ€™s why we later **train an NLP classifier**: to make the model understand the sentiment from text alone, even without ratings.

--- 

### ğŸš€ Project Pipeline

1. **Preprocessing (DONE)**

-  Implemented in src/data/preprocess.py to clean and normalize raw comments.
-  Output: data/processed/data-google-reviews_clean.csv
-  Area: NLP (text cleaning & normalization)

2. **Embedding Extraction (WORK IN PROGRESS)**

-  Implemented in src/features/embeddings.py (e.g., using TF-Hub multilingual USE).
-  Output: artifacts/features/embeddings.npy
-  Area: NLP / Representation Learning (vectorization of text)

3. **Classifier Training (TO DO)**

-  Implemented in src/models/classifier.py to train a sentiment/spam detection model.
-  Output: artifacts/models/
-  Area: NLP + Machine Learning / Neural Networks

4. **Author Linking (TO DO)**

-  Implemented in src/linking/similarity.py + src/linking/clustering.py to cluster possible repeated authors.
-  Output: artifacts/predictions/author_clusters.csv
-  Area: NLP + Unsupervised Learning (clustering)

5. **Evaluation (TO DO)**

-  Implemented in src/eval/ for classification and linking metrics.
-  Area: General Machine Learning (evaluation metrics)

6. **Automated Tests (DONE)**

-  Unit tests located in tests/ for each module.
-  Area: Software Engineering / Best Practices

---

## ğŸ“Œ End-to-end Sentiment Analysis Pipeline

This project builds a sentiment classifier (positive / neutral / negative) for Google Reviews.
The workflow has 4 main steps:

1ï¸âƒ£ Generate Labels (Heuristic)

Create reviews_labeled.csv from the raw dataset using the labeling script:

# Linux / macOS
```bash
python -m src.data.heuristics_labeling \
  --in "data/raw/data-google-reviews.csv" \
  --out "data/processed/reviews_labeled.csv"
```

# Windows PowerShell
``` powershell
python -m src.data.heuristics_labeling --in "data/raw/data-google-reviews.csv" --out "data/processed/reviews_labeled.csv"
```

â¡ï¸ Output: data/processed/reviews_labeled.csv with column label.

2ï¸âƒ£ Train the TensorFlow Model

```bash
python -m src.models.classifier_tf
```
âœ”ï¸ Output:
Model â†’ artifacts/models/keras/model_full/
Metrics â†’ artifacts/models/keras/train_metrics.json

3ï¸âƒ£ Inference (Use the Trained Model)

``` python
from src.models.classifier_tf import SentimentClassifierTF

clf = SentimentClassifierTF("artifacts/models/keras/model_full")
clf.load()

preds = clf.predict([
    "Excelente atendimento e doces incrÃ­veis!",
    "PreÃ§o razoÃ¡vel, nada demais.",
    "Demorou muito e veio errado."
])
print(preds)  # ['positive', 'neutral', 'negative']

```

4ï¸âƒ£ Evaluation (Accuracy, F1, Confusion Matrix)

``` python
from pathlib import Path
import pandas as pd
from src.models.classifier_tf import SentimentClassifierTF
from src.eval.metrics_classification import compute_metrics, save_metrics

df = pd.read_csv("data/processed/reviews_labeled.csv")
texts, y_true = df["message"], df["label"]

clf = SentimentClassifierTF("artifacts/models/keras/model_full")
clf.load()
y_pred = clf.predict(texts)

m = compute_metrics(y_true, y_pred)
save_metrics(m, Path("artifacts/predictions"), "keras_fullset")

print("accuracy:", m["accuracy"])

```

âœ”ï¸ Output:
artifacts/predictions/keras_fullset_metrics.json
artifacts/predictions/keras_fullset_confusion_matrix.csv

---

## ğŸ“‚ Project Structure

```text
google-reviews-nlp/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ artifacts/                # generated outputs
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ predictions/
â”‚
â”œâ”€â”€ data/                     # datasets
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ clean-data-google-reviews.csv
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_train_classifier.ipynb
â”‚   â”œâ”€â”€ 03_linking_experiments.ipynb
â”‚   â””â”€â”€ .ipynb_checkpoints/
â”‚
â”œâ”€â”€ src/                      # source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ heuristics_labeling.py
â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â”‚
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â”œâ”€â”€ metrics_classification.py
â”‚   â”‚   â””â”€â”€ metrics_linking.py
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ embeddings_tfhub.py
â”‚   â”‚   â””â”€â”€ stylometry.py
â”‚   â”‚
â”‚   â”œâ”€â”€ link_author/
â”‚   â”‚   â”œâ”€â”€ build_similarity_graph.py
â”‚   â”‚   â””â”€â”€ cluster_dbscan.py
â”‚   â”‚
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ classifier_tf.py
â”‚       â””â”€â”€ siamese_tf.py
â”‚
â””â”€â”€ tests/                    # unit tests
    â”œâ”€â”€ src
         â”œâ”€â”€ data
             â””â”€â”€ test_preprocess.py
```

---

## âš™ï¸ Tech Stack
- ğŸ **Python 3.10+**
- ğŸ”¶ **TensorFlow / Keras** â€“ model training
- ğŸŒ **TensorFlow Hub** â€“ multilingual embeddings (USE / LaBSE)
- ğŸ“Š **scikit-learn** â€“ clustering (DBSCAN, HDBSCAN) & metrics
- ğŸ“š **spaCy (pt)** â€“ optional preprocessing for Portuguese
- ğŸ“ˆ **pandas / matplotlib / seaborn** â€“ analysis & visualization

---

## ğŸ”¬ Workflow

1. **Exploratory Data Analysis** (`01_eda.ipynb`)
   - Inspect raw reviews, distributions & anomalies
   - Apply basic cleaning

2. **Classification** (`02_train_classifier.ipynb`)
   - Train sentiment / topic / spam classifiers
   - Evaluate with accuracy, F1-score & confusion matrix

3. **Author Linking** (`03_linking_experiments.ipynb`)
   - Generate embeddings + stylometry features
   - Build similarity graph & cluster comments
   - Identify **candidate same-author groups**

---

## ğŸ“Š Outputs
- ğŸ“‘ **Classification reports** (JSON, PNG plots)
- ğŸ¤– **Saved TensorFlow models** (`.h5`, `.pkl`)
- ğŸ”— **Similarity graphs** of comments
- ğŸ‘¥ **Author cluster assignments** (`author_clusters.csv`)

---

## ğŸ§ª Running the Unit Tests

Follow the steps below to execute the test suite for src/data/preprocess.py.

ğŸ“¦ Prerequisites
Python 3.10+
pip (virtual environment recommended)
âš™ï¸ Setup & Install

**from the repository root**
``` bash
python -m venv .venv
Activate the venv
```

ğŸªŸ Windows
``` powershell
.venv\Scripts\activate
```

ğŸ macOS / ğŸ§ Linux
``` bash
source .venv/bin/activate

Install deps
pip install -r requirements.txt
```

**â–¶ï¸ Run the Tests**
#run the whole suite
``` bash
python -m pytest -q
```

**ğŸ› ï¸ Troubleshooting**

ğŸ ModuleNotFoundError: No module named 'src'
Make sure you run from the repo root and use the module form:
``` bash
python -m pytest -q
```

---

## âš ï¸ Disclaimer
This project is intended for **research and educational purposes only**.
Author linking is **probabilistic** and should be interpreted as **candidate same-author groups**, not definitive proof.
All datasets used are either **publicly available** or **synthetic**.

---

## ğŸš€ Next Steps
- Improve weak labeling for "suspect vs legitimate" reviews.
- Train a Siamese/contrastive model for authorship verification.
- Add temporal & behavioral features (time, frequency).
- Create an interactive dashboard for results.
