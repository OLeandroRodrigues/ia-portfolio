{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e19418",
   "metadata": {},
   "source": [
    "\n",
    "# 01 â€” EDA (Exploratory Data Analysis)\n",
    "\n",
    "**Project:** Google Reviews NLP  \n",
    "**Goal:** Explore the raw dataset to understand data quality, distributions, and guide cleaning/splitting decisions.\n",
    "\n",
    "> Tip: Run this notebook from the project root's virtual environment. Keep outputs light before committing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad3c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports & setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "\n",
    "# Ensure plots show inline (typical in Jupyter)\n",
    "%matplotlib inline\n",
    "\n",
    "# Paths (adjust if needed)\n",
    "PROJECT_ROOT = Path.cwd()  # if running from the repo root\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"RAW DATA PATH:\", DATA_RAW)\n",
    "print(\"PROCESSED PATH:\", DATA_PROCESSED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f4f26",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724913cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from glob import glob\n",
    "\n",
    "def robust_read_csv(path: Path, sep=\",\", encoding=\"utf-8\", **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Read CSV with common fallbacks for encoding/separators.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=sep, encoding=encoding, **kwargs)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, sep=sep, encoding=\"latin-1\", **kwargs)\n",
    "    except pd.errors.ParserError:\n",
    "        # try semicolon as fallback\n",
    "        return pd.read_csv(path, sep=\";\", encoding=encoding, **kwargs)\n",
    "\n",
    "def load_all_raw(data_dir: Path) -> pd.DataFrame:\n",
    "    csvs = sorted(list(data_dir.glob(\"*.csv\")))\n",
    "    if not csvs:\n",
    "        print(f\"[WARN] No CSVs found in {data_dir}. Place raw files there.\")\n",
    "        return pd.DataFrame()\n",
    "    frames = []\n",
    "    for p in csvs:\n",
    "        try:\n",
    "            df = robust_read_csv(p)\n",
    "            df[\"__source_file\"] = p.name\n",
    "            frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to read {p}: {e}\")\n",
    "    out = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "    return out\n",
    "\n",
    "df = load_all_raw(DATA_RAW)\n",
    "print(\"Rows:\", len(df))\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55a0ee",
   "metadata": {},
   "source": [
    "## Quick Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"dtypes:\\n\", df.dtypes)\n",
    "print(\"\\nNulls per column:\\n\", df.isna().sum())\n",
    "\n",
    "# Numeric/overall describe\n",
    "display(df.describe(include=\"all\").transpose().head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea50bc",
   "metadata": {},
   "source": [
    "## Light Normalization (in-notebook helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb93ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Expected columns (adjust to your scraper schema):\n",
    "# name | rating | number_of_photos | message\n",
    "expected_cols = [\"name\", \"rating\", \"number_of_photos\", \"message\"]\n",
    "for c in expected_cols:\n",
    "    if c not in df.columns:\n",
    "        print(f\"[WARN] Column missing: {c}\")\n",
    "\n",
    "# Safe copies / coercions\n",
    "df[\"name\"] = df.get(\"name\", pd.Series([None]*len(df))).fillna(\"\").astype(str).str.strip()\n",
    "df[\"message\"] = df.get(\"message\", pd.Series([None]*len(df))).fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "# rating: try to coerce; keep original as 'rating_raw'\n",
    "if \"rating\" in df.columns:\n",
    "    df[\"rating_raw\"] = df[\"rating\"]\n",
    "    df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "else:\n",
    "    df[\"rating\"] = np.nan\n",
    "\n",
    "# photos: normalize to string \"0\" when empty/non-numeric (to match your test expectations)\n",
    "if \"number_of_photos\" in df.columns:\n",
    "    photos = df[\"number_of_photos\"].fillna(\"\").astype(str).str.strip()\n",
    "    photos = photos.mask(photos.eq(\"\"), \"0\")\n",
    "    photos = photos.str.replace(r\"\\.0+$\", \"\", regex=True)\n",
    "    photos = photos.where(photos.str.fullmatch(r\"\\d+\"), \"0\")\n",
    "    df[\"number_of_photos_norm\"] = photos\n",
    "else:\n",
    "    df[\"number_of_photos_norm\"] = \"0\"\n",
    "\n",
    "# Basic sanity\n",
    "display(df.head(10)[[\"name\",\"rating\",\"number_of_photos\",\"number_of_photos_norm\",\"message\"] if \"number_of_photos\" in df.columns else [\"name\",\"rating\",\"number_of_photos_norm\",\"message\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3970a",
   "metadata": {},
   "source": [
    "## Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd8fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if df[\"rating\"].notna().any():\n",
    "    vc = df[\"rating\"].value_counts(dropna=True).sort_index()\n",
    "    print(vc)\n",
    "\n",
    "    plt.figure()\n",
    "    vc.plot(kind=\"bar\")\n",
    "    plt.title(\"Rating Distribution\")\n",
    "    plt.xlabel(\"Rating\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"[INFO] No numeric ratings found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1366fe16",
   "metadata": {},
   "source": [
    "## Message Length & Text Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b71b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def word_count(s: str) -> int:\n",
    "    if not isinstance(s, str):\n",
    "        return 0\n",
    "    # simple token split (space)\n",
    "    return len([t for t in s.split() if t.strip()])\n",
    "\n",
    "df[\"len_chars\"] = df[\"message\"].apply(lambda s: len(s) if isinstance(s, str) else 0)\n",
    "df[\"len_words\"] = df[\"message\"].apply(word_count)\n",
    "df[\"has_url\"] = df[\"message\"].str.contains(r\"http[s]?://\", case=False, regex=True, na=False)\n",
    "\n",
    "display(df[[\"name\",\"rating\",\"len_chars\",\"len_words\",\"has_url\"]].head(10))\n",
    "\n",
    "plt.figure()\n",
    "df[\"len_words\"].hist(bins=30)\n",
    "plt.title(\"Message Length (words)\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "if df[\"rating\"].notna().any():\n",
    "    # Boxplot len_words by rating\n",
    "    plt.figure()\n",
    "    grouped = [g[\"len_words\"].dropna().values for _, g in df.groupby(df[\"rating\"])]\n",
    "    labels = [str(int(k)) if not np.isnan(k) else \"NaN\" for k, _ in df.groupby(df[\"rating\"])]\n",
    "    plt.boxplot(grouped, labels=labels, showfliers=False)\n",
    "    plt.title(\"Message Length by Rating\")\n",
    "    plt.xlabel(\"Rating\")\n",
    "    plt.ylabel(\"Words\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf07ae",
   "metadata": {},
   "source": [
    "## Authors & Potential Spam Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b85b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"name\" in df.columns:\n",
    "    author_counts = df[\"name\"].value_counts().head(20)\n",
    "    print(\"Top authors by number of reviews:\")\n",
    "    print(author_counts)\n",
    "\n",
    "    # Suspects: many reviews or ultra-short messages\n",
    "    suspects = df[(df[\"len_words\"] <= 3) | (df[\"has_url\"])]\n",
    "    print(\"\\nSuspect rows (first 10):\")\n",
    "    display(suspects.head(10)[[\"name\",\"rating\",\"len_words\",\"has_url\",\"message\"]])\n",
    "else:\n",
    "    print(\"[INFO] 'name' column not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155ed75",
   "metadata": {},
   "source": [
    "## Duplicate Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple dupe check by exact message (can be expanded later)\n",
    "if not df.empty:\n",
    "    dup_by_msg = df[df.duplicated(subset=[\"message\"], keep=False)].sort_values(\"message\").head(20)\n",
    "    print(\"Potential duplicate messages (first 20):\")\n",
    "    display(dup_by_msg[[\"name\",\"rating\",\"message\"]])\n",
    "else:\n",
    "    print(\"[INFO] DataFrame is empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7660f57",
   "metadata": {},
   "source": [
    "## Save a Lightweight Processed Preview (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fefa287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PREVIEW_PATH = DATA_PROCESSED / \"reviews_preview.csv\"\n",
    "cols = [\"name\",\"rating\",\"number_of_photos_norm\",\"len_chars\",\"len_words\",\"has_url\",\"message\"]\n",
    "existing_cols = [c for c in cols if c in df.columns]\n",
    "if not df.empty and existing_cols:\n",
    "    os.makedirs(DATA_PROCESSED, exist_ok=True)\n",
    "    df[existing_cols].to_csv(PREVIEW_PATH, index=False)\n",
    "    print(f\"Saved preview -> {PREVIEW_PATH}\")\n",
    "else:\n",
    "    print(\"[INFO] Nothing to save (no data or columns missing).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924f7c7",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusions & Next Steps\n",
    "\n",
    "- Validate rating distribution and class balance.\n",
    "- Confirm text cleaning rules (e.g., empty â†’ drop? min length threshold?).\n",
    "- Standardize `number_of_photos` as **string \"0\"** when empty to satisfy unit tests.\n",
    "- Inspect authors with many reviews for potential spam/bots.\n",
    "- Decide language handling (Portuguese vs. others) if needed.\n",
    "- Proceed to `src/data/preprocess.py` (production-grade cleaning) and `src/data/split.py` (stratified + grouped split).\n",
    "\n",
    "> Tip: Keep this notebook focused on **exploration**. Production logic should live in `src/` and be covered by tests in `tests/`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
